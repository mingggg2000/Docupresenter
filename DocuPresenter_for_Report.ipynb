{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Gu538iUXjbk"
      },
      "source": [
        "# DocuPresenter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HurWt-a6XviJ"
      },
      "source": [
        "## Setup\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLS5wD2rXiJV"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGAtjt2QQSNa",
        "outputId": "8eb856f5-8c67-4797-a0a9-b8916502a5e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (2.106.0)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (0.22.0)\n",
            "Requirement already satisfied: google-auth<3.0.0.dev0,>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (2.17.3)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (0.1.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (2.11.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (4.1.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.61.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.20.3)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.31.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (4.9)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.15.0->google-api-python-client) (3.1.1)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (0.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade google-api-python-client"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "novGtQNDNgGY"
      },
      "source": [
        "To read pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "66Z1p1iJqkCw",
        "outputId": "0f76cd6d-0d41-44e3-c66a-4198f277b714"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install PyPDF2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXkfPPQkNpNF",
        "outputId": "409821f9-9ad9-45b4-df7a-0a974e956202"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "wkhtmltopdf is already the newest version (0.12.6-2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 23 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!apt-get update\n",
        "!apt-get install -y wkhtmltopdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Gw2j-7ENYRM",
        "outputId": "d60a75d0-c6ae-4aff-a1ed-5f468d50e9da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: weasyprint in /usr/local/lib/python3.10/dist-packages (60.1)\n",
            "Requirement already satisfied: CairoSVG in /usr/local/lib/python3.10/dist-packages (2.7.1)\n",
            "Requirement already satisfied: pydyf>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from weasyprint) (0.8.0)\n",
            "Requirement already satisfied: cffi>=0.6 in /usr/local/lib/python3.10/dist-packages (from weasyprint) (1.16.0)\n",
            "Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.10/dist-packages (from weasyprint) (1.1)\n",
            "Requirement already satisfied: tinycss2>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from weasyprint) (1.2.1)\n",
            "Requirement already satisfied: cssselect2>=0.1 in /usr/local/lib/python3.10/dist-packages (from weasyprint) (0.7.0)\n",
            "Requirement already satisfied: Pyphen>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from weasyprint) (0.14.0)\n",
            "Requirement already satisfied: Pillow>=9.1.0 in /usr/local/lib/python3.10/dist-packages (from weasyprint) (9.4.0)\n",
            "Requirement already satisfied: fonttools[woff]>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from weasyprint) (4.43.1)\n",
            "Requirement already satisfied: cairocffi in /usr/local/lib/python3.10/dist-packages (from CairoSVG) (1.6.1)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from CairoSVG) (0.7.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=0.6->weasyprint) (2.21)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from cssselect2>=0.1->weasyprint) (0.5.1)\n",
            "Requirement already satisfied: zopfli>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from fonttools[woff]>=4.0.0->weasyprint) (0.2.3)\n",
            "Requirement already satisfied: brotli>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from fonttools[woff]>=4.0.0->weasyprint) (1.1.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->weasyprint) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install weasyprint CairoSVG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V9wcoGLVYJWP"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as palm\n",
        "\n",
        "import textwrap\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tW4iO3TlYL_w"
      },
      "source": [
        "API Key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oegCrohmYNfx"
      },
      "outputs": [],
      "source": [
        "palm.configure(api_key='AIzaSyDlnJAOpPRzJLT1IeBisvc-Fe4Eg71O9AI')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HepWsBEMYXYf"
      },
      "source": [
        "Choosing a Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKLX2HiDYPzB"
      },
      "outputs": [],
      "source": [
        "models = [m for m in palm.list_models() if 'embedText' in m.supported_generation_methods]\n",
        "\n",
        "model = models[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioGxtVltPh-K"
      },
      "source": [
        "## Retrieve files from data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RbfdKR1PfLW",
        "outputId": "f5cf92c6-0d9d-4368-ccbb-962956660b35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive to Google Colab.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1464
        },
        "id": "zNQ_sCqNpa2O",
        "outputId": "bd304c93-32f1-45d8-bfcd-1edf3895e478"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                   Filename  \\\n",
              "0  Google Hackathon Report Presentation.pdf   \n",
              "\n",
              "                                                Text  \n",
              "0  Google\\nHackathon\\nReport\\nTeam\\n10:\\nPrompt\\n...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-12e1c901-e2a4-433f-a8f6-83fbe2d47f90\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Filename</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Google Hackathon Report Presentation.pdf</td>\n",
              "      <td>Google\\nHackathon\\nReport\\nTeam\\n10:\\nPrompt\\n...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-12e1c901-e2a4-433f-a8f6-83fbe2d47f90')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-12e1c901-e2a4-433f-a8f6-83fbe2d47f90 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-12e1c901-e2a4-433f-a8f6-83fbe2d47f90');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "import os\n",
        "import PyPDF2\n",
        "import pandas as pd\n",
        "\n",
        "folder_path = \"/content/gdrive/MyDrive/Report\"\n",
        "pdf_dict = {}\n",
        "\n",
        "# Check if the folder exists\n",
        "if os.path.exists(folder_path):\n",
        "    # Iterate over files in the folder\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith(\".pdf\"):  # Check if it's a PDF file\n",
        "            pdf_path = os.path.join(folder_path, filename)\n",
        "\n",
        "            with open(pdf_path, 'rb') as pdf_file:\n",
        "                pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
        "\n",
        "                # Extract text from each page\n",
        "                text = \"\"\n",
        "                for page in pdf_reader.pages:\n",
        "                    page_text = page.extract_text()\n",
        "                    if page_text:  # Ensure there's text on the page\n",
        "                        text += page_text + \" \"  # Add space after each page's content\n",
        "\n",
        "                # Optionally truncate text if too long for your application\n",
        "                shortened_text = text[:9900] if len(text) > 9900 else text\n",
        "\n",
        "                # Add the shortened text to the dictionary\n",
        "                pdf_dict[filename] = shortened_text\n",
        "else:\n",
        "    print(f\"Folder {folder_path} does not exist!\")\n",
        "\n",
        "# Convert the dictionary to a dataframe\n",
        "df = pd.DataFrame(list(pdf_dict.items()), columns=['Filename', 'Text'])\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "id": "JbCzgirhimmg",
        "outputId": "bad97336-74b9-4629-c290-343f105ea91c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                   Filename  \\\n",
              "0  Google Hackathon Report Presentation.pdf   \n",
              "\n",
              "                                                Text  \\\n",
              "0  Google\\nHackathon\\nReport\\nTeam\\n10:\\nPrompt\\n...   \n",
              "\n",
              "                                          Embeddings  \n",
              "0  [-0.02529152, -0.025373043, -0.008314696, 0.03...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e91d3302-4901-4110-b282-18229babf594\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Filename</th>\n",
              "      <th>Text</th>\n",
              "      <th>Embeddings</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Google Hackathon Report Presentation.pdf</td>\n",
              "      <td>Google\\nHackathon\\nReport\\nTeam\\n10:\\nPrompt\\n...</td>\n",
              "      <td>[-0.02529152, -0.025373043, -0.008314696, 0.03...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e91d3302-4901-4110-b282-18229babf594')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e91d3302-4901-4110-b282-18229babf594 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e91d3302-4901-4110-b282-18229babf594');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "# Get the embeddings of each text and add to an embeddings column in the dataframe\n",
        "def embed_fn(text):\n",
        "  return palm.generate_embeddings(model=model, text=text)['embedding']\n",
        "\n",
        "df['Embeddings'] = df['Text'].apply(embed_fn)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akpfU2F3i1LH"
      },
      "source": [
        "##Query here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hpeEnyUiivkX"
      },
      "outputs": [],
      "source": [
        "topic = \"Google Hackathon Report\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IpUvTYQviwT4"
      },
      "outputs": [],
      "source": [
        "def find_best_passage(topic, dataframe):\n",
        "  \"\"\"\n",
        "  Compute the distances between the query and each document in the dataframe\n",
        "  using the dot product.\n",
        "  \"\"\"\n",
        "  query_embedding = palm.generate_embeddings(model=model, text=topic)\n",
        "  dot_products = np.dot(np.stack(dataframe['Embeddings']), query_embedding['embedding'])\n",
        "  idx = np.argmax(dot_products)\n",
        "  return dataframe.iloc[idx]['Text'] # Return text from index with max value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "TaTo7Wvmi5as",
        "outputId": "b10d8216-c60a-490b-ecd3-eb14c90b305f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Google\\nHackathon\\nReport\\nTeam\\n10:\\nPrompt\\nto\\nSlides\\nNovember\\n4,\\n2023\\nAniruddh\\nIngle,\\nSylvanne\\nBraganza,\\nSherry\\nLi,\\nHritik\\nBhansali,\\nCece\\nZhang\\nProject\\nOverview\\nOur\\nproject\\naimed\\nto\\ntransform\\ntext-based\\ncontent\\ninto\\nengaging\\npresentations\\nwith\\nthe\\nhelp\\nof\\nGoogle's\\npowerful\\nPaLM2\\nAPI.\\nBy\\nharnessing\\nthe\\ncapabilities\\nof\\nthis\\ncutting-edge\\nnatural\\nlanguage\\nprocessing\\ntool,\\nwe\\nstreamlined\\nthe\\nprocess\\nof\\ncreating\\ndynamic\\npresentations\\nfrom\\ntextual\\ninformation.\\nWhether\\nit\\nwas\\nconverting\\nlengthy\\nreports\\ninto\\ninformative\\nslides\\nor\\ntransforming\\nwritten\\ncontent\\ninto\\ncompelling\\nspoken\\npresentations,\\nour\\nteam\\nenhanced\\nthe\\nefficiency\\nand\\neffectiveness\\nof\\ncommunication.\\nWith\\nthe\\nPaLM2\\nAPI,\\nwe\\nautomated\\nthe\\nstructuring\\nand\\nsummarizing\\nof\\ninformation,\\nallowing\\nusers\\nto\\neffortlessly\\ntransform\\ntheir\\nideas\\nand\\ndata\\ninto\\nengaging\\nspoken\\npresentations.\\nThis\\nproject\\nis\\na\\ngame-changer\\nin\\nsimplifying\\nthe\\npresentation\\ncreation\\nprocess,\\nmaking\\nit\\nan\\ninvaluable\\ntool\\nfor\\nprofessionals,\\neducators,\\nand\\nanyone\\nlooking\\nto\\ncommunicate\\ntheir\\nideas\\neffectively.\\nMakerSuite\\nfor\\nPrompt\\nEngineering\\nIn\\nour\\nproject,\\nwe\\nleveraged\\nGoogle's\\nMakerSuite\\nfor\\nprompt\\nengineering.\\nInitially,\\nwe\\nexplored\\ndifferent\\nprompt\\ntypes,\\nincluding\\ntext\\nprompts,\\ndata\\nprompts,\\nand\\nchat\\nprompts.\\nAfter\\nexperimenting\\nwith\\nthese\\noptions,\\nwe\\nfound\\nthat\\nthe\\ndata\\nprompt\\nwas\\nthe\\nmost\\nsuitable\\nchoice\\nfor\\nour\\nproject\\naims\\ndue\\nto\\nits\\nability\\nto\\ntailor\\nthe\\ninput\\nand\\noutput\\nstructure\\naccording\\nto\\nour\\nproject’s\\nspecific\\nrequirements\\n(text\\nto\\nMarkdown-formatted\\nscript).\\nData\\nprompts\\nwork\\nby\\ntaking\\ncustom\\ninstructions\\nprovided\\nby\\nusers.\\nIn\\nour\\ncase,\\nwe\\nasked\\nit\\nto\\ngenerate\\na\\npresentation\\nin\\nMarkdown\\nscript\\nformat\\ntailored\\nto\\na\\nspecific\\nage\\ngroup.\\nThen\\nwe\\ngive\\nthe\\nmodel\\nspecific\\ninput\\nand\\noutput\\nexamples\\nto\\nwork\\nwith.\\nThese\\nprompts\\ngive\\nthe\\nmodel\\nexamples\\nto\\nreplicate.\\nGoogle\\ncalls\\nthese\\n“few-shot\\nprompts.”\\nThey\\nserved\\nas\\ntraining\\ndata\\nfor\\nthe\\nmodel.\\nOver\\ntime,\\nwe\\nfine-tuned\\nthese\\nexamples\\nbased\\non\\nthe\\nspecific\\ncontent\\nstructure\\nand\\nstyle\\nwe\\nwanted\\nfor\\nour\\npresentations.\\nThis\\niterative\\nprocess\\nallowed\\nthe\\nmodel\\nto\\nlearn\\nand\\nadapt\\nto\\nour\\nrequirements.\\nWe\\nproceeded\\nstep\\nby\\nstep.\\nOur\\ninitial\\ngoal\\nwas\\nto\\nuse\\nthis\\ndata\\nprompt\\nto\\nefficiently\\nbreak\\nblocks\\nof\\ntext\\ninto\\nbullet\\npoints,\\nsimplifying\\nthe\\ncontent\\nstructuring\\nprocess.\\nOnce\\nwe\\nachieved\\nthis,\\nwe\\ntook\\nit\\na\\nstep\\nfurther\\nby\\ninstructing\\nthe\\ndata\\nprompt\\nto\\nformat\\nthe\\nextracted\\nbullet\\npoints\\nas\\na\\nMarkdown\\nscript\\nfor\\na\\ntwo-slide\\npresentation,\\nconsisting\\nof\\none\\ntitle\\nslide\\nand\\none\\ncontent\\nslide.\\nFinally,\\nwe\\ntailored\\nour\\nexamples\\nto\\ngenerate\\nmulti-slide\\npresentation\\nMarkdown\\noutputs,\\nproviding\\neven\\ngreater\\nflexibility\\nand\\nautomation\\nin\\nthe\\npresentation\\ncreation\\nprocess. Our\\ninput\\ntexts\\nwere\\ninitially\\ntaken\\nfrom\\nWikipedia\\narticles;\\nour\\noutputs\\nwere\\ninitially\\nwritten\\nbased\\non\\na\\ntemplate\\nHTML\\nMarkdown\\ncode\\n(Appendix\\nA)\\nthat\\nwe\\nmanually\\nfilled\\nin.\\nIn\\nMakerSuite,\\nwe\\nwere\\nthen\\nable\\nto\\nhave\\nthe\\nmodel\\nuse\\nour\\nexamples\\n(Appendix\\nB)\\nto\\ngenerate\\nmore\\nexamples.\\nWe\\nalso\\nexperimented\\nwith\\nthe\\nunderlying\\nLLM\\nat\\nthis\\nstage.\\nLLM\\nresponses\\nexhibit\\nboth\\ndeterministic\\nand\\nrandom\\ncharacteristics.\\nWhen\\nyou\\ninput\\na\\nprompt\\nto\\nan\\nLLM,\\nit\\ngenerates\\na\\nprobability\\ndistribution\\nover\\npotential\\ntokens\\n(words)\\nlikely\\nto\\nappear\\nnext.\\nThis\\ninitial\\nstage\\nis\\nentirely\\ndeterministic;\\nthe\\nLLM\\nconsistently\\nproduces\\nthe\\nsame\\ndistribution\\nwhen\\ngiven\\nthe\\nsame\\nprompt.\\nHowever,\\nin\\nthe\\nsubsequent\\nstage,\\nthe\\nLLM\\ntransforms\\nthese\\ndistributions\\ninto\\nactual\\ntext\\nresponses\\nusing\\nvarious\\ndecoding\\nmethods.\\nA\\nstraightforward\\ndecoding\\napproach\\nmight\\nselect\\nthe\\nmost\\nprobable\\ntoken\\nat\\neach\\nstep,\\nensuring\\ndeterminism.\\nAlternatively,\\nyou\\ncan\\nopt\\nfor\\na\\nresponse\\ngeneration\\nmethod\\nthat\\ninvolves\\nrandom\\nsampling\\nfrom\\nthe\\nmodel's\\noutput\\ndistribution,\\nintroducing\\na\\ndegree\\nof\\nrandomness.\\nThis\\nstochastic\\nbehavior\\ncan\\nbe\\ncontrolled\\nby\\nadjusting\\nthe\\ntemperature\\nsetting.\\nA\\ntemperature\\nof\\n0\\nresults\\nin\\ndeterministic\\ntoken\\nselection,\\nwhile\\nhigher\\ntemperatures\\nintroduce\\nmore\\nrandomness,\\nyielding\\nunexpected\\nand\\nsurprising\\nmodel\\nresponses.\\n(LLM\\nConcepts\\nGuide,\\n2023)\\nIn\\nour\\nprompt\\ngeneration\\nstage,\\nwe\\nchanged\\nthis\\ntemperature\\nsetting\\nto\\nachieve\\na\\nbroad\\nrange\\nof\\nexample\\nprompts\\nthat\\nstill\\nformatted\\nthe\\noutput\\nas\\nour\\ndesired\\nMarkdown\\ncode\\nscript.\\nMakerSuite\\nthen\\nallowed\\nus\\nto\\nadd\\nthe\\nnewly\\ngenerated\\nexamples\\nthat\\nwe\\napproved\\nas\\nmore\\nexamples\\nto\\ntrain\\nthe\\nmodel.\\nOnce\\nwe\\nwere\\nhappy\\nwith\\nthe\\nmodel’s\\nresponses\\nto\\nour\\ntest\\ninputs,\\nwe\\neasily\\nexported\\nit\\nto\\nPython\\ncode\\n(Appendix\\nC)\\nin\\nGoogle\\nColab,\\nand\\ncalled\\nthe\\nsame\\nmodel\\nusing\\nthe\\nPaLM\\nAPI.\\nDocument\\nSearch\\nwith\\nEmbeddings\\nThis\\ntechnique\\nallows\\nfor\\nsearching\\ndocuments\\nby\\ncomparing\\ntheir\\nembedded\\nrepresentations,\\nor\\nvectors\\nof\\nnumbers\\nthat\\ncapture\\nthe\\nsemantic\\nmeaning\\nof\\ntext.\\nThe\\nsteps\\nare\\nas\\nfollows.\\nFirst,\\nwe\\nmust\\ngenerate\\nembedded\\nrepresentations\\nfor\\nall\\nof\\nthe\\ntext\\nin\\nthe\\ndocument(s).\\nThis\\ncan\\nbe\\ndone\\nusing\\na\\npre-trained\\nembedding\\nmodel,\\na\\nfew\\nof\\nwhich\\nare\\nprovided\\nby\\nGoogle.\\nNext,\\nwe\\nmust\\ngenerate\\nan\\nembedded\\nrepresentation\\nof\\nthe\\nquery\\ntext.\\nThis\\nis\\ndone\\nusing\\nthe\\nsame\\nembedding\\nmodel\\nas\\nused\\nin\\nthe\\nfirst\\nstep.\\nNow,\\nwe\\ncan\\ncompare\\nthe\\nembedded\\nrepresentation\\nof\\nthe\\nquery\\ntext\\nto\\nthe\\nembedded\\nrepresentations\\nof\\nthe\\ninput\\ndocument(s).\\nThis\\nis\\ndone\\nusing\\nsimilarity\\nmetrics,\\nsuch\\nas\\ndistance\\ndeterminations.\\nFinally,\\nwe\\nmust\\nreturn\\nthe\\nresults\\nwith\\nthe\\nhighest\\nscores.\\nWe\\nbased\\nour\\ncode\\non\\nthe\\nexample\\nprovided\\nby\\nGoogle\\nhere:\\nhttps://developers.generativeai.google/examples/doc_search_emb\\n. This\\ncode\\nallowed\\nus\\nto\\nuse\\nthe\\nPaLM\\nAPI\\nto\\ncreate\\nembeddings\\nso\\nthat\\nwe\\ncould\\nperform\\ndocument\\nsearch.\\nIn\\nour\\ncode,\\nwe\\ncan\\ngenerate\\nembeddings,\\nbuild\\nan\\nembeddings\\ndatabase,\\nand\\nthen\\ndocument\\nsearch\\nwith\\na\\nQ&A\\nsystem.\\nThe\\nembedded\\nrepresentations\\nare\\ncompared\\nusing\\nthe\\ndot\\nproduct\\nof\\nthe\\nvectors,\\nranging\\nfrom\\n-1\\nto\\n1.\\nOne\\nchallenge\\nencountered\\nin\\nour\\nproject\\nwas\\nthat\\nthe\\nembedding\\nsystem\\nwe\\nused\\nhad\\na\\nlimitation\\nwhere\\nit\\nonly\\nworked\\nwith\\na\\nmaximum\\nof\\n10,000\\nbytes\\nof\\ndata.\\nConsequently,\\nthis\\nmeant\\nthat\\nwe\\ncould\\nnot\\ninclude\\nmore\\nthan\\napproximately\\n5,000\\nwords\\nin\\nthe\\ninput\\ndocument.\\nTo\\naddress\\nthis\\nlimitation,\\nwe\\nimplemented\\na\\nline\\nin\\nour\\ncode\\nwhich\\nprocessed\\ntext\\nstored\\nin\\nthe\\nvariable\\ncleaned_text.\\nInitially,\\nit\\nencodes\\nthis\\ntext\\ninto\\nbytes\\nusing\\nthe\\nUTF-8\\nencoding,\\nwhich\\nis\\na\\ncommon\\npractice\\nto\\nensure\\nthat\\ntext\\ncan\\nbe\\nrepresented\\nas\\na\\nsequence\\nof\\nbytes.\\nFollowing\\nthe\\nencoding\\nstep,\\nthe\\ncode\\nthen\\nextracts\\nthe\\nfirst\\n9900\\nbytes\\nfrom\\nthe\\nencoded\\nbyte\\nsequence\\nusing\\nslicing.\\nThis\\nensured\\nthat\\nour\\ntext\\nremains\\nwithin\\nthe\\nacceptable\\nsize\\nrange.\\nFinally,\\nthe\\nsliced\\nbyte\\nsequence\\nis\\ndecoded\\nback\\ninto\\na\\ntext\\nstring\\nusing\\nthe\\nUTF-8\\nencoding,\\nwith\\nthe\\n'ignore'\\noption\\nspecified\\nfor\\nerror\\nhandling.\\nIf\\nany\\ndecoding\\nissues\\narise\\ndue\\nto\\ntext\\ntruncation,\\nthis\\noption\\ninstructs\\nPython\\nto\\nskip\\nthose\\nproblematic\\ncharacters\\nand\\ncontinue\\ndecoding\\nthe\\nrest\\nof\\nthe\\ntext,\\nthus\\npreserving\\nas\\nmuch\\nof\\nthe\\noriginal\\ncontent\\nas\\npossible.\\nWe\\nthen\\nincorporated\\nour\\nengineered\\nprompts\\ninto\\nour\\ndocument\\nsearch\\nwith\\nembeddings\\ncode.\\nThere\\nare\\nseveral\\nadvantages\\nto\\nusing\\ndocument\\nsearch\\nwith\\nembedded\\ntext\\nover\\nkeyword-based,\\ntraditional\\nsearch\\nmethods\\nfor\\nour\\nproject.\\nThe\\nmain\\nreason\\nis\\nthat\\nit\\nis\\nmore\\nrobust\\nto\\nsynonyms,\\nmisspellings,\\nwhich\\nmight\\ncrop\\nup\\nin\\nour\\nusers’\\nqueries\\nor\\nin\\nthe\\nconversion\\nfrom\\nthe\\ninput\\nPDF\\ndocument(s)\\nto\\nstring(s).\\nAnother\\nadvantage\\nis\\nthat\\nit\\ncan\\nbe\\nused\\nto\\nsearch\\nfor\\ndocuments\\nin\\na\\nvariety\\nof\\nlanguages,\\nsince\\nit\\ndoes\\njust\\ndepend\\non\\nsemantic\\nmeanings.\\nGoogle\\nAPI\\nOur\\nfinal\\nstep\\nwas\\nconnecting\\nour\\ninput\\nand\\noutput\\nPDF\\nfiles\\nto\\nour\\nGoogle\\nDrive\\naccount\\nfor\\nease\\nof\\nuse\\nand\\nseamless\\naccess.\\nWe\\nwere\\nable\\nto\\ndo\\nthis\\nusing\\nGoogle\\nAPIs\\nExplorer.\\nThe\\nGoogle\\nDrive\\nAPI\\nallows\\nour\\nmodel\\nto\\naccess\\nresources\\nfrom\\nGoogle\\nDrive.\\nHow\\nto\\nUse\\nWe\\nhave\\nincluded\\na\\nReadMe\\nfile\\nin\\nour\\nsubmission.\\nBriefly,\\na\\nuser\\ncan\\nupload\\na\\nPDF\\ndocument\\ninto\\na\\nfolder\\nin\\ntheir\\nGoogle\\nDrive.\\nThey\\ncan\\nthen\\nadjust\\nthe\\nquery\\nto\\nspecify\\nage\\nor\\neducation\\nlevel.\\nFinally,\\nthey\\nrun\\nour\\npython\\nscript\\nto\\ngenerate\\na\\nPDF\\npresentation\\nof\\nslides,\\nwhich\\nwill\\nbe\\nsaved\\nback\\ninto\\ntheir\\nGoogle\\nDrive. Future\\nDirections\\nWe\\nplan\\nto\\ncontinue\\nto\\nbuild\\non\\nthis\\nproject\\nfor\\nthe\\nremainder\\nof\\nthe\\nmini.\\nAs\\npreviously\\ndiscussed,\\nwe\\nare\\npresently\\nutilizing\\nthe\\nPaLM\\nAPI\\nto\\ngenerate\\nembeddings\\nthat\\nenable\\nus\\nto\\nperform\\nsearches\\nwithin\\nPDF\\ndocuments\\nstored\\nin\\na\\nGoogle\\nDrive\\nusing\\nour\\nqueries.\\nSo\\nfar,\\nour\\ntesting\\nhas\\npredominantly\\nfocused\\non\\nprompts\\nin\\nthe\\nEnglish\\nlanguage.\\nHowever,\\nas\\ndocument\\nsearch\\nwith\\nembedded\\ntext\\nis\\nadaptable\\nand\\ncapable\\nof\\nsearching\\nin\\nvarious\\nlanguages,\\nwe\\nintend\\nto\\nextend\\nour\\ntesting\\nto\\nencompass\\nlanguages\\nbeyond\\nEnglish,\\nincluding\\nChinese\\nand\\nHindi,\\nto\\nbuild\\non\\nthis\\nproject.\\nFurthermore,\\nwe\\nintend\\nto\\nbroaden\\nour\\nscope\\nby\\nexploring\\nadditional\\ntypes\\nand\\nlengths\\nof\\ndocuments\\nthat\\ncan\\nbe\\nsearched\\nusing\\nour\\nqueries.\\nCurrently,\\nour\\ntesting\\nis\\nlimited\\nto\\nsearching\\nthrough\\nPDF\\ndocuments.\\nHowever,\\nwe\\nare\\nplanning\\nto\\nexpand\\nour\\nsearch\\ncapabilities\\nby\\nincluding\\nWord\\ndocuments\\nand\\nwebsites\\nin\\nour\\ntesting,\\naiming\\nto\\nenhance\\nthe\\nversatility\\nand\\nadaptability\\nof\\nour\\nquery. \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "passage = find_best_passage(topic, df)\n",
        "passage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XoluVKPfjTt3"
      },
      "outputs": [],
      "source": [
        "def make_prompt(topic, relevant_passage):\n",
        "  escaped = relevant_passage.replace(\"'\", \"\").replace('\"', \"\").replace(\"\\n\", \" \")\n",
        "  prompt = textwrap.dedent(\"\"\"You are a helpful and informative bot that creates presentations using text from the reference passage included below. \\\n",
        "  I am a teacher for a group of 13-year-old students, please output markdown scripts\n",
        "  If the passage is irrelevant to the presentation, you may ignore it.\n",
        "  Topic: '{topic}'\n",
        "  PASSAGE: '{relevant_passage}'\n",
        "\n",
        "    ANSWER:\n",
        "  \"\"\").format(topic=topic, relevant_passage=escaped)\n",
        "\n",
        "  return prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_aaADvxjavK",
        "outputId": "32222271-11c1-48df-a61e-95f6d7fe3963"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are a helpful and informative bot that creates presentations using text from the reference passage included below.   I am a teacher for a group of 13-year-old students, please output markdown scripts\n",
            "  If the passage is irrelevant to the presentation, you may ignore it.\n",
            "  Topic: 'Google Hackathon Report'\n",
            "  PASSAGE: 'Google Hackathon Report Team 10: Prompt to Slides November 4, 2023 Aniruddh Ingle, Sylvanne Braganza, Sherry Li, Hritik Bhansali, Cece Zhang Project Overview Our project aimed to transform text-based content into engaging presentations with the help of Googles powerful PaLM2 API. By harnessing the capabilities of this cutting-edge natural language processing tool, we streamlined the process of creating dynamic presentations from textual information. Whether it was converting lengthy reports into informative slides or transforming written content into compelling spoken presentations, our team enhanced the efficiency and effectiveness of communication. With the PaLM2 API, we automated the structuring and summarizing of information, allowing users to effortlessly transform their ideas and data into engaging spoken presentations. This project is a game-changer in simplifying the presentation creation process, making it an invaluable tool for professionals, educators, and anyone looking to communicate their ideas effectively. MakerSuite for Prompt Engineering In our project, we leveraged Googles MakerSuite for prompt engineering. Initially, we explored different prompt types, including text prompts, data prompts, and chat prompts. After experimenting with these options, we found that the data prompt was the most suitable choice for our project aims due to its ability to tailor the input and output structure according to our project’s specific requirements (text to Markdown-formatted script). Data prompts work by taking custom instructions provided by users. In our case, we asked it to generate a presentation in Markdown script format tailored to a specific age group. Then we give the model specific input and output examples to work with. These prompts give the model examples to replicate. Google calls these “few-shot prompts.” They served as training data for the model. Over time, we fine-tuned these examples based on the specific content structure and style we wanted for our presentations. This iterative process allowed the model to learn and adapt to our requirements. We proceeded step by step. Our initial goal was to use this data prompt to efficiently break blocks of text into bullet points, simplifying the content structuring process. Once we achieved this, we took it a step further by instructing the data prompt to format the extracted bullet points as a Markdown script for a two-slide presentation, consisting of one title slide and one content slide. Finally, we tailored our examples to generate multi-slide presentation Markdown outputs, providing even greater flexibility and automation in the presentation creation process. Our input texts were initially taken from Wikipedia articles; our outputs were initially written based on a template HTML Markdown code (Appendix A) that we manually filled in. In MakerSuite, we were then able to have the model use our examples (Appendix B) to generate more examples. We also experimented with the underlying LLM at this stage. LLM responses exhibit both deterministic and random characteristics. When you input a prompt to an LLM, it generates a probability distribution over potential tokens (words) likely to appear next. This initial stage is entirely deterministic; the LLM consistently produces the same distribution when given the same prompt. However, in the subsequent stage, the LLM transforms these distributions into actual text responses using various decoding methods. A straightforward decoding approach might select the most probable token at each step, ensuring determinism. Alternatively, you can opt for a response generation method that involves random sampling from the models output distribution, introducing a degree of randomness. This stochastic behavior can be controlled by adjusting the temperature setting. A temperature of 0 results in deterministic token selection, while higher temperatures introduce more randomness, yielding unexpected and surprising model responses. (LLM Concepts Guide, 2023) In our prompt generation stage, we changed this temperature setting to achieve a broad range of example prompts that still formatted the output as our desired Markdown code script. MakerSuite then allowed us to add the newly generated examples that we approved as more examples to train the model. Once we were happy with the model’s responses to our test inputs, we easily exported it to Python code (Appendix C) in Google Colab, and called the same model using the PaLM API. Document Search with Embeddings This technique allows for searching documents by comparing their embedded representations, or vectors of numbers that capture the semantic meaning of text. The steps are as follows. First, we must generate embedded representations for all of the text in the document(s). This can be done using a pre-trained embedding model, a few of which are provided by Google. Next, we must generate an embedded representation of the query text. This is done using the same embedding model as used in the first step. Now, we can compare the embedded representation of the query text to the embedded representations of the input document(s). This is done using similarity metrics, such as distance determinations. Finally, we must return the results with the highest scores. We based our code on the example provided by Google here: https://developers.generativeai.google/examples/doc_search_emb . This code allowed us to use the PaLM API to create embeddings so that we could perform document search. In our code, we can generate embeddings, build an embeddings database, and then document search with a Q&A system. The embedded representations are compared using the dot product of the vectors, ranging from -1 to 1. One challenge encountered in our project was that the embedding system we used had a limitation where it only worked with a maximum of 10,000 bytes of data. Consequently, this meant that we could not include more than approximately 5,000 words in the input document. To address this limitation, we implemented a line in our code which processed text stored in the variable cleaned_text. Initially, it encodes this text into bytes using the UTF-8 encoding, which is a common practice to ensure that text can be represented as a sequence of bytes. Following the encoding step, the code then extracts the first 9900 bytes from the encoded byte sequence using slicing. This ensured that our text remains within the acceptable size range. Finally, the sliced byte sequence is decoded back into a text string using the UTF-8 encoding, with the ignore option specified for error handling. If any decoding issues arise due to text truncation, this option instructs Python to skip those problematic characters and continue decoding the rest of the text, thus preserving as much of the original content as possible. We then incorporated our engineered prompts into our document search with embeddings code. There are several advantages to using document search with embedded text over keyword-based, traditional search methods for our project. The main reason is that it is more robust to synonyms, misspellings, which might crop up in our users’ queries or in the conversion from the input PDF document(s) to string(s). Another advantage is that it can be used to search for documents in a variety of languages, since it does just depend on semantic meanings. Google API Our final step was connecting our input and output PDF files to our Google Drive account for ease of use and seamless access. We were able to do this using Google APIs Explorer. The Google Drive API allows our model to access resources from Google Drive. How to Use We have included a ReadMe file in our submission. Briefly, a user can upload a PDF document into a folder in their Google Drive. They can then adjust the query to specify age or education level. Finally, they run our python script to generate a PDF presentation of slides, which will be saved back into their Google Drive. Future Directions We plan to continue to build on this project for the remainder of the mini. As previously discussed, we are presently utilizing the PaLM API to generate embeddings that enable us to perform searches within PDF documents stored in a Google Drive using our queries. So far, our testing has predominantly focused on prompts in the English language. However, as document search with embedded text is adaptable and capable of searching in various languages, we intend to extend our testing to encompass languages beyond English, including Chinese and Hindi, to build on this project. Furthermore, we intend to broaden our scope by exploring additional types and lengths of documents that can be searched using our queries. Currently, our testing is limited to searching through PDF documents. However, we are planning to expand our search capabilities by including Word documents and websites in our testing, aiming to enhance the versatility and adaptability of our query. '\n",
            "\n",
            "    ANSWER:\n",
            "\n"
          ]
        }
      ],
      "source": [
        "prompt = make_prompt(topic, passage)\n",
        "print(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1YvfJ8LQzjf",
        "outputId": "13e16125-1f69-4d1f-8658-e97348c667c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```\n",
            "# Title Slide\n",
            "\n",
            "## Google Hackathon Report\n",
            "\n",
            "### Team 10: Prompt to Slides\n",
            "\n",
            "### November 4, 2023\n",
            "\n",
            "### Aniruddh Ingle, Sylvanne Braganza, Sherry Li, Hritik Bhansali, Cece Zhang\n",
            "\n",
            "## Project Overview\n",
            "\n",
            "Our project aimed to transform text-based content into engaging presentations with the help of Google's powerful PaLM2 API. By harnessing the capabilities of this cutting-edge natural language processing tool, we streamlined the process of creating dynamic presentations from textual information. Whether it was converting lengthy reports into informative slides or transforming written content into compelling spoken presentations, our team enhanced the efficiency and effectiveness of communication. With the PaLM2 API, we automated the structuring and summarizing of information, allowing users to effortlessly transform their ideas and data into engaging spoken presentations. This project is a game-changer in simplifying the presentation creation process, making it an invaluable tool for professionals, educators, and anyone looking to communicate their ideas effectively.\n",
            "\n",
            "## MakerSuite for Prompt Engineering\n",
            "\n",
            "In our project, we leveraged Google's MakerSuite for prompt engineering. Initially, we explored different prompt types, including text prompts, data prompts, and chat prompts. After experimenting with these options, we found that the data prompt was the most suitable choice for our project aims due to its ability to tailor the input and output structure according to our project's specific requirements (text to Markdown-formatted script). Data prompts work by taking custom instructions provided by users. In our case, we asked it to generate a presentation in Markdown script format tailored to a specific age group. Then we give the model specific input and output examples to work with. These prompts give the model examples to replicate. Google calls these \"few-shot prompts.\" They served as training data for the model. Over time, we fine-tuned these examples based on the specific content structure and style we wanted for our presentations. This iterative process allowed the model to learn and adapt to our requirements.\n",
            "\n",
            "## Document Search with Embeddings\n",
            "\n",
            "This technique allows for searching documents by comparing their embedded representations, or vectors of numbers that capture the semantic meaning of text. The steps are as follows. First, we must generate embedded representations for all of the text in the document(s). This can be done using a pre-trained embedding model, a few of which are provided by Google. Next, we must generate an embedded representation of the query text. This is done using the same embedding model as used in the first step. Now, we can compare the embedded representation of the query text to the embedded representations of the input document(s). This is done using similarity metrics, such as distance determinations. Finally, we must return the results with the highest scores.\n",
            "\n",
            "## Google API\n",
            "\n",
            "Our final step was connecting our input and output PDF files to our Google Drive account for ease of use and seamless access. We were able to do this using Google APIs Explorer. The Google Drive API allows our model to access resources from Google Drive.\n",
            "\n",
            "## How to Use\n",
            "\n",
            "To use our project, users can follow these steps:\n",
            "\n",
            "1. Upload a PDF document into a folder in their Google Drive.\n",
            "2. Adjust the query to specify age or education level.\n",
            "3. Run our python script to generate a PDF presentation of slides, which will be saved back into their Google Drive.\n",
            "\n",
            "## Future Directions\n",
            "\n",
            "We plan to continue to build on this project for the remainder of the mini. As previously discussed, we are presently utilizing the PaLM API to generate embeddings that enable us to perform searches within PDF documents stored in a Google Drive using our queries. So far, our testing has predominantly focused on prompts in the English language. However, as document search with embedded text is adaptable and capable of searching in various languages, we intend to extend our testing to encompass languages beyond English, including Chinese and Hindi, to build on this project. Furthermore, we intend to broaden our scope by exploring additional types and lengths of documents that can be searched using our queries. Currently, our testing is limited to searching through PDF documents. However, we are planning to expand our search capabilities by including Word documents and websites in our testing, aiming to enhance the versatility and adaptability of our query.\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "text_models = [m for m in palm.list_models() if 'generateText' in m.supported_generation_methods]\n",
        "\n",
        "text_model = text_models[0]\n",
        "\n",
        "temperature = 0.5\n",
        "answer = palm.generate_text(prompt=prompt,\n",
        "                            model=text_model,\n",
        "                            temperature=temperature,\n",
        "                            max_output_tokens=1000)\n",
        "print(answer.result)\n",
        "\n",
        "llm_output= answer.result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBdkMf8WNO4u"
      },
      "source": [
        "## Convert .md to pdf and save to Gdrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oavhJ1gNh5g3",
        "outputId": "e90ed7f9-c076-401f-e5b8-30c8385fea3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The presentation PDF has been created and saved to /content/gdrive/MyDrive/Report/presentation.pdf.\n"
          ]
        }
      ],
      "source": [
        "from weasyprint import HTML\n",
        "import markdown\n",
        "\n",
        "# Ensure llm_output is a string and strip unnecessary characters if present.\n",
        "llm_output = llm_output.strip(\"```\").strip()\n",
        "\n",
        "# Convert Markdown content to HTML\n",
        "html_content = markdown.markdown(llm_output)\n",
        "\n",
        "# HTML and CSS for the presentation-like format\n",
        "\n",
        "# HTML and CSS for the presentation-like format\n",
        "presentation_html = f\"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "    <meta charset=\"utf-8\">\n",
        "    <title>Presentation</title>\n",
        "    <style>\n",
        "        @page {{\n",
        "            size: A4 landscape;\n",
        "            margin: 0mm;\n",
        "        }}\n",
        "        body {{\n",
        "            font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif;\n",
        "            margin: 0;\n",
        "            padding: 0;\n",
        "            display: block;\n",
        "        }}\n",
        "        section {{\n",
        "            width: 80%;\n",
        "            max-width: 1280px;\n",
        "            margin: 1cm auto;\n",
        "            page-break-after: always;\n",
        "            page-break-inside: avoid;\n",
        "            display: block;\n",
        "        }}\n",
        "        h1, h2, h3, h4 {{\n",
        "            text-align: center;\n",
        "            margin-top: 0.5cm;\n",
        "            margin-bottom: 0.5cm;\n",
        "        }}\n",
        "        p, li {{\n",
        "            font-size: 24px;\n",
        "            line-height: 1.5;\n",
        "            text-align: left;\n",
        "            margin-left: 10%;\n",
        "            margin-right: 10%;\n",
        "        }}\n",
        "        ul, ol {{\n",
        "            padding-left: 20px;\n",
        "        }}\n",
        "    </style>\n",
        "</head>\n",
        "<body>\n",
        "    {html_content}\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "# Set the output file name\n",
        "output_file_name = \"presentation.pdf\"\n",
        "\n",
        "# Set the path to save the PDF file (modify as needed)\n",
        "pdf_file_path = f\"/content/gdrive/MyDrive/Report/{output_file_name}\"\n",
        "\n",
        "# Generate the PDF from the HTML string and save it to the specified path\n",
        "HTML(string=presentation_html).write_pdf(pdf_file_path)\n",
        "\n",
        "print(f\"The presentation PDF has been created and saved to {pdf_file_path}.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}